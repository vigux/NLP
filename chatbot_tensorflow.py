"""
Chatbot sencillo con TensorFlow/Keras
- Clasifica la intenciÃ³n del usuario y responde con una frase adecuada.
- Enfoque: pipeline minimalista (TextVectorization + Embedding + Pooling + Dense).
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models

# =========================
# 1) INTENCIONES (DATASET)
# =========================
# Conjunto pequeÃ±o de intents para un bot bÃ¡sico.
INTENTS = {
    "saludo": {
        "patterns": [
            "hola", "hola, Â¿quÃ© tal?", "buenos dÃ­as", "buenas tardes", "hey", "quÃ© onda"
        ],
        "responses": [
            "Â¡Hola! Â¿En quÃ© puedo ayudarte?",
            "Â¡Un gusto saludarte! Â¿QuÃ© te gustarÃ­a saber?"
        ]
    },
    "ayuda": {
        "patterns": [
            "Â¿quÃ© puedes hacer?", "ayuda", "necesito ayuda", "Â¿cÃ³mo funcionas?", "no sÃ© quÃ© preguntar"
        ],
        "responses": [
            "Puedo responder saludos, despedidas y dudas bÃ¡sicas. Â¡IntÃ©ntalo!",
            "Puedo orientarte de manera general. Por ejemplo: salÃºdame o despÃ­dete."
        ]
    },
    "agradecimiento": {
        "patterns": [
            "gracias", "muchas gracias", "te lo agradezco", "mil gracias"
        ],
        "responses": [
            "Â¡Con gusto! Â¿Algo mÃ¡s en lo que te pueda apoyar?",
            "Para servirte. Â¿Deseas preguntar otra cosa?"
        ]
    },
    "despedida": {
        "patterns": [
            "adiÃ³s", "hasta luego", "nos vemos", "bye", "me voy"
        ],
        "responses": [
            "Â¡Hasta luego! Que tengas un excelente dÃ­a.",
            "Â¡Nos vemos! Vuelve cuando quieras."
        ]
    }
}

FALLBACK_RESPONSES = [
    "No estoy seguro de entender. Â¿PodrÃ­as reformularlo?",
    "AÃºn estoy aprendiendo. Intenta con: 'hola', 'ayuda', 'gracias' o 'adiÃ³s'."
]

# =====================================
# 2) CONSTRUCCIÃ“N DEL CONJUNTO DE DATOS
# =====================================
def build_dataset(intents_dict):
    """Crea listas X (textos) e y (etiquetas) a partir de INTENTS."""
    texts, labels = [], []
    for intent, data in intents_dict.items():
        for p in data["patterns"]:
            texts.append(p.lower().strip())
            labels.append(intent)
    return texts, labels

texts, labels = build_dataset(INTENTS)

# Creamos mapas etiqueta <-> Ã­ndice
unique_labels = sorted(list(set(labels)))
label2idx = {lab: i for i, lab in enumerate(unique_labels)}
idx2label = {i: lab for lab, i in label2idx.items()}
y = np.array([label2idx[l] for l in labels], dtype=np.int32)

# ======================================
# 3) TEXTVECTORIZATION (TOKENIZACIÃ“N/ID)
# ======================================
MAX_TOKENS = 10000          # vocabulario mÃ¡ximo
MAX_LEN = 16                # longitud mÃ¡xima por frase

text_vec = layers.TextVectorization(
    standardize="lower_and_strip_punctuation",  # minÃºsculas + sin puntuaciÃ³n
    split="whitespace",
    max_tokens=MAX_TOKENS,
    output_mode="int",
    output_sequence_length=MAX_LEN
)
text_vec.adapt(np.array(texts))                 # aprende vocabulario del dataset

X = text_vec(np.array(texts))                   # textos -> secuencias de IDs

# ============================
# 4) MODELO (Keras, muy simple)
# ============================
# Arquitectura minimalista:
# Embedding -> GlobalAveragePooling1D -> Dense(hidden) -> Dense(softmax)
EMBED_DIM = 64

inputs = layers.Input(shape=(MAX_LEN,), dtype=tf.int64, name="input_ids")
x = layers.Embedding(input_dim=MAX_TOKENS, output_dim=EMBED_DIM, name="embed")(inputs)
x = layers.GlobalAveragePooling1D(name="avg_pool")(x)
x = layers.Dense(64, activation="relu")(x)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(len(unique_labels), activation="softmax", name="cls")(x)

model = models.Model(inputs, outputs)
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Entrenamiento rÃ¡pido (dataset pequeÃ±o)
model.fit(X, y, epochs=30, batch_size=8, verbose=0)

# =====================================
# 5) PREDICCIÃ“N + RESPUESTA DEL CHATBOT
# =====================================
CONFIDENCE_THRESHOLD = 0.6  # si la confianza es menor, usamos FALLBACK

def predict_intent(user_text: str):
    """Retorna (intent, confianza)."""
    seq = text_vec(np.array([user_text.lower().strip()]))
    probs = model.predict(seq, verbose=0)[0]
    idx = int(np.argmax(probs))
    return idx2label[idx], float(probs[idx])

def get_bot_response(intent: str) -> str:
    """Elige una respuesta aleatoria asociada a la intenciÃ³n."""
    import random
    return random.choice(INTENTS[intent]["responses"])

# ============================
# 6) BUCLE DE DIÃLOGO EN CONSOLA
# ============================
def chat():
    print("Chatbot TensorFlow (sencillo). Escribe 'salir' para terminar.")
    while True:
        user = input("\nTÃº: ").strip()
        if user.lower() in ["salir", "exit", "quit"]:
            print("Bot: Â¡Hasta luego! ğŸ‘‹")
            break

        intent, conf = predict_intent(user)
        if conf < CONFIDENCE_THRESHOLD:
            # Respuesta de reserva si el modelo no estÃ¡ seguro
            print(f"Bot: {np.random.choice(FALLBACK_RESPONSES)}")
        else:
            # Respuesta asociada a la intenciÃ³n detectada
            print(f"Bot: ({intent}, conf={conf:.2f}) {get_bot_response(intent)}")

if __name__ == "__main__":
    chat()